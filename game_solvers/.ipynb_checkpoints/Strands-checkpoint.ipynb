{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3bc55d1-f37c-41be-b99e-a2abd5e180a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4618b844-c1b5-49cc-9fff-8cb827d1ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = np.array(open('../data/scrabble_dict.txt', 'r').read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad5343f-240d-4688-aeef-b266d0abf8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle = \"\"\"\n",
    "ACNARA\n",
    "YMTIOC\n",
    "TAGSCB\n",
    "JECIAT\n",
    "GUIOIC\n",
    "LGRMRE\n",
    "EDTACN\n",
    "RUEVAD\n",
    "\"\"\"\n",
    "n_wds = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f2a71c9-fb45-4f92-a8a6-27949c7a6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all words with 4+ letters in grid\n",
    "lgrid = np.array([list(r) for r in puzzle.split('\\n') if r != ''])\n",
    "grr, grc = lgrid.shape\n",
    "rr = np.repeat(np.arange(grr)+1, grc)\n",
    "cc = np.tile(np.arange(grc)+1, grr)\n",
    "lgrid = np.pad(lgrid, 1, constant_values='#')\n",
    "\n",
    "found_str = np.expand_dims(lgrid[rr, cc], 1)\n",
    "\n",
    "avail_grid = np.repeat(-np.ones(tuple([1, *lgrid.shape]), dtype=int), \n",
    "                       rr.shape[0], \n",
    "                       axis=0)\n",
    "avail_grid[np.arange(avail_grid.shape[0]), 1:-1, 1:-1] = 0\n",
    "avail_grid[np.arange(avail_grid.shape[0]), rr, cc] = 1\n",
    "\n",
    "found_wds = list()\n",
    "found_wds_map = list()\n",
    "lnum = 1\n",
    "\n",
    "while found_str.shape[0] > 0:\n",
    "    rr = np.repeat(rr, 8) + np.tile([-1, -1, 0, 1, 1, 1, 0, -1], rr.shape[0])\n",
    "    cc = np.repeat(cc, 8) + np.tile([0, 1, 1, 1, 0, -1, -1, -1], cc.shape[0])\n",
    "    avail_grid = np.repeat(avail_grid, 8, axis=0)\n",
    "    filt = avail_grid[np.arange(avail_grid.shape[0]), rr, cc] == 0\n",
    "    \n",
    "    rr, cc, avail_grid = [i[filt] for i in(rr, cc, avail_grid)]\n",
    "    found_str = np.column_stack((np.repeat(found_str, 8, axis=0)[filt], \n",
    "                                 lgrid[rr, cc]))\n",
    "    \n",
    "    fstr = found_str.reshape(-1).view(f'<U{found_str.shape[1]}')\n",
    "    lnum += 1\n",
    "    avail_grid[np.arange(avail_grid.shape[0]), rr, cc] = lnum\n",
    "    valid_str = np.unique(all_words.view('<U1')\n",
    "                                   .reshape(all_words.shape[0], -1)[:, :found_str.shape[1]]\n",
    "                                   .reshape(-1)\n",
    "                                   .view(f'<U{found_str.shape[1]}'))\n",
    "    \n",
    "    vstr_filt = np.isin(fstr, valid_str)\n",
    "    rr, cc, found_str, fstr, avail_grid = [i[vstr_filt] for i in(rr, cc, found_str, fstr, avail_grid)]\n",
    "\n",
    "    if lnum >= 4:\n",
    "        wordfilt = np.isin(fstr, all_words)\n",
    "        found_wds += fstr[wordfilt].tolist()\n",
    "        found_wds_map += [avail_grid[wordfilt][:, 1:-1, 1:-1]]\n",
    "\n",
    "found_wds = np.array(['', *found_wds])\n",
    "found_wds_map = np.concatenate([np.zeros_like(found_wds_map[0][:1]),\n",
    "                                *found_wds_map],\n",
    "                               axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba27023-3998-4fcd-98df-fbb6b98876ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all pairs of non-overlapping words in Pandas DF\n",
    "# x = np.repeat(np.arange(found_wds.shape[0]), found_wds.shape[0])\n",
    "# y = np.tile(np.arange(found_wds.shape[0]), found_wds.shape[0])\n",
    "# pair_ix = np.column_stack((x, y))[y > x]\n",
    "# for r in range(grr):\n",
    "#     for c in range(grc):\n",
    "#         pair_ix = pair_ix[np.any(found_wds_map[:, r, c][pair_ix] == 0, axis=1)]\n",
    "\n",
    "# # Get all sets of {n_wds-1} non-overlapping words\n",
    "# pair_ix = pair_ix.merge(pair_ix.rename(columns={'wd1': 'wd2'}), \n",
    "#                         on='wd0')\\\n",
    "#                  .merge(pair_ix.rename(columns={'wd0': 'wd1',\n",
    "#                                                 'wd1': 'wd2'}), \n",
    "#                         on=['wd1', 'wd2'])\n",
    "# pair_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267ce5a-ec0a-453e-b2cb-c7cbaa6da095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poss_wds_ix = np.expand_dims(np.arange(found_wds.shape[0]), 1)\n",
    "# poss_map = np.copy(found_wds_map)\n",
    "\n",
    "# expix = np.arange(found_wds.shape[0]*poss_wds_ix.shape[0])\\\n",
    "#             [np.tile(np.arange(found_wds.shape[0]), poss_wds_ix.shape[0]) \n",
    "#              > np.repeat(poss_wds_ix[:, -1], found_wds.shape[0])]\n",
    "# possix = np.repeat(poss_wds_ix[:, -1], found_wds.shape[0])[expix]\n",
    "# addix = np.tile(np.arange(found_wds.shape[0]), poss_wds_ix.shape[0])[expix]\n",
    "# ovlp_filt = np.all((poss_map[possix] == 0) | (found_wds_map[addix] == 0), axis=(1, 2))\n",
    "\n",
    "# poss_wds_ix = np.column_stack((poss_wds_ix[possix][ovlp_filt], \n",
    "#                                np.arange(found_wds.shape[0])[addix][ovlp_filt]))\n",
    "# poss_map = poss_map[possix][ovlp_filt]\\\n",
    "#                + np.where(found_wds_map[addix][ovlp_filt] > 0,\n",
    "#                           found_wds_map[addix][ovlp_filt] + 10,\n",
    "#                           found_wds_map[addix][ovlp_filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "74b8f3d2-fb29-4ccd-bc5d-6a8e5214b69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 30\n",
      "0 1 83\n",
      "0 2 1541\n",
      "0 3 4999\n",
      "0 4 17595\n",
      "0 5 27904\n",
      "1 0 53133\n",
      "1 1 88391\n",
      "1 2 169213\n",
      "1 3 196561\n",
      "1 4 306940\n",
      "1 5 306940\n",
      "2 0 707905\n",
      "2 1 964575\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 444. MiB for an array with shape (465213105,) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[610]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(grc):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Expand next word possibilities, keep only words that overlap (rr, cc)\u001b[39;00m\n\u001b[32m      9\u001b[39m     poss_ix = np.repeat(np.arange(poss_map.shape[\u001b[32m0\u001b[39m]),\n\u001b[32m     10\u001b[39m                         np.where(poss_map[:, rr, cc] == \u001b[32m0\u001b[39m, found_wds.shape[\u001b[32m0\u001b[39m], \u001b[32m1\u001b[39m))\n\u001b[32m     11\u001b[39m     nw_ix = np.arange(poss_ix.shape[\u001b[32m0\u001b[39m])\\\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m             - np.maximum.accumulate(np.where(\u001b[43mposs_ix\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposs_ix\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[32m     13\u001b[39m                                              np.arange(poss_ix.shape[\u001b[32m0\u001b[39m]), \n\u001b[32m     14\u001b[39m                                              \u001b[32m0\u001b[39m))\n\u001b[32m     16\u001b[39m     filt = (nw_ix == \u001b[32m0\u001b[39m) | (found_wds_map[nw_ix, rr, cc] != \u001b[32m0\u001b[39m)\n\u001b[32m     17\u001b[39m     poss_ix, nw_ix = (i[filt] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (poss_ix, nw_ix))\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 444. MiB for an array with shape (465213105,) and data type bool"
     ]
    }
   ],
   "source": [
    "poss_wds = np.empty((1, 0), dtype=found_wds.dtype)\n",
    "poss_map = np.zeros_like(found_wds_map[:1])\n",
    "poss_wds_done = []\n",
    "poss_map_done = []\n",
    "\n",
    "for rr in range(grr):\n",
    "    for cc in range(grc):\n",
    "        # Create indices for next word possibilities\n",
    "        poss_ix = np.repeat(np.arange(poss_map.shape[0]),\n",
    "                            np.where(poss_map[:, rr, cc] == 0, found_wds.shape[0], 1))\n",
    "        nw_ix = np.arange(poss_ix.shape[0])\\\n",
    "                - np.maximum.accumulate(np.where(poss_ix != np.append([-1], poss_ix[:-1]), \n",
    "                                                 np.arange(poss_ix.shape[0]), \n",
    "                                                 0))\n",
    "        filt = (nw_ix == 0) | (found_wds_map[nw_ix, rr, cc] != 0)\n",
    "        poss_ix, nw_ix = (i[filt] for i in (poss_ix, nw_ix))\n",
    "        for r in range(grr):\n",
    "            for c in range(grc):\n",
    "                filt = (poss_map[poss_ix, r, c] == 0) | (found_wds_map[nw_ix, r, c] == 0)\n",
    "                poss_ix, nw_ix = (i[filt] for i in (poss_ix, nw_ix))\n",
    "\n",
    "        # Generate words list for each possible scenario\n",
    "        poss_wds = np.column_stack((poss_wds[poss_ix], found_wds[nw_ix]))\n",
    "        for c in range(poss_wds.shape[1]-2, -1, -1):\n",
    "            filt = poss_wds[:, c] == ''\n",
    "            poss_wds[filt, c:-1] = poss_wds[filt, c+1:]\n",
    "            poss_wds[filt, -1] = ''\n",
    "        poss_wds = poss_wds[:, :np.sum(np.sum(poss_wds != '', axis=0) > 0)]\n",
    "\n",
    "        # Count words for each possible scenario\n",
    "        poss_nwds = np.sum(poss_wds != '', axis=1)\n",
    "\n",
    "        # Generate grid map for each possible scenario\n",
    "        poss_map = poss_map[poss_ix]\\\n",
    "                   + np.where(found_wds_map[nw_ix] > 0, \n",
    "                              found_wds_map[nw_ix] + (np.expand_dims(poss_nwds, (1, 2)) * 100), \n",
    "                              found_wds_map[nw_ix])\n",
    "        poss_map[nw_ix == 0, rr, cc] = np.where(poss_map[nw_ix == 0, rr, cc] == 0, \n",
    "                                                -1, \n",
    "                                                poss_map[nw_ix == 0, rr, cc])\n",
    "\n",
    "        # Remove scenarios where required number of words reached\n",
    "        filt = poss_nwds == n_wds\n",
    "        poss_wds_done += [poss_wds[filt]]\n",
    "        poss_map_done += [poss_map[filt]]\n",
    "        poss_wds = poss_wds[~filt]\n",
    "        poss_map = poss_map[~filt]\n",
    "\n",
    "        print(rr, cc, poss_wds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "ead3231d-612e-4049-ac14-5bcd704bd6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TARA', 'MAGI', 'CABOC', 'TEGG', '', ''], dtype='<U10')"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poss_wds[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "e7d2849e-a428-4e0e-bb8e-b6583b7aff09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,  -1,  -1, 102, 103, 104],\n",
       "       [ -1, 201, 101,  -1, 304,  -1],\n",
       "       [401, 202, 203,   0, 305, 303],\n",
       "       [  0, 402,   0, 204, 302,   0],\n",
       "       [403,   0,   0,   0,   0, 301],\n",
       "       [  0, 404,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poss_map[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "7be16e86-11f3-4f7f-a6d2-42bb6b93a16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964575, 8, 6)"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poss_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "352635a9-1cae-4e30-a21c-685d3c80a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgcheck = np.append(-2*np.ones_like(poss_map[:, :1, :]),\n",
    "                    poss_map, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "1f5e969a-a33e-4a76-a120-79e853a51656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,   -1,   -1, ...,   -1,   -1, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]],\n",
       "\n",
       "       [[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,   -1,   -1, ...,   -1,   -1, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]],\n",
       "\n",
       "       [[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,   -1,   -1, ...,   -1,   -1, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,  101,  205, ...,  201,  305, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,  401,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]],\n",
       "\n",
       "       [[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,  101,  205, ...,  201,  301, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]],\n",
       "\n",
       "       [[9999, 9999, 9999, ..., 9999, 9999, 9999],\n",
       "        [9999,   -2,   -2, ...,   -2,   -2, 9999],\n",
       "        [9999,  101,  208, ...,   -1,   -1, 9999],\n",
       "        ...,\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999,    0,    0, ...,    0,    0, 9999],\n",
       "        [9999, 9999, 9999, ..., 9999, 9999, 9999]]], shape=(964575, 11, 8))"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgcheck = np.pad(np.append(-2*np.ones_like(poss_map[:, :1, :]),\n",
    "                           poss_map, axis=1), \n",
    "                 ((0, 0), (1, 1), (1, 1)), \n",
    "                 'constant', \n",
    "                 constant_values=9999)\n",
    "pgcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "1afbfa80-6e15-42f4-91cc-f43f148095f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2,  -2,  -2,  -2,  -2,  -2],\n",
       "       [ -1,  -1,  -1, 102, 103, 104],\n",
       "       [ -1, 201, 101,  -1, 304,  -1],\n",
       "       [401, 202, 203,   0, 305, 303],\n",
       "       [  0, 402,   0, 204, 302,   0],\n",
       "       [403,   0,   0,   0,   0, 301],\n",
       "       [  0, 404,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgcheck[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "bb7c972e-d454-44f0-9814-ce0c2a618af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]]])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv1 = (np.arange(8)+1).reshape(2, 2, 2)\n",
    "tv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "79919895-0603-40fe-82ca-6249ff0ebf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0],\n",
       "        [0, 1, 2, 0],\n",
       "        [0, 3, 4, 0],\n",
       "        [0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0],\n",
       "        [0, 5, 6, 0],\n",
       "        [0, 7, 8, 0],\n",
       "        [0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(tv1, ((0, 0), (1, 1), (1, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
